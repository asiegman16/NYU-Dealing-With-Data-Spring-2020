{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas and Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Pandas = 'Python Data Analysis Library' (https://pandas.pydata.org/)\n",
    "import matplotlib  # A 2D plotting library (https://matplotlib.org/)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Statistical data visualization (https://seaborn.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started with Data Frames, a table structure of rows and columns used in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by creating a new data frame using pd.DataFrame\n",
    "# We are then going to use a 'list of dictionaries', which we'll touch on briefly\n",
    "\n",
    "df = pd.DataFrame([ \n",
    "    {\"First Name\": \"Alex\", \"Last Name\": \"Siegman\"}, \n",
    "    {\"First Name\": \"John\", \"Last Name\": \"Doe\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's dig a bit deeper to understand what just happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"First Name\": \"Alex\", \"Last Name\": \"Siegman\"}\n",
    "               # <key>     <value>     <key>      <value>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary['First Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary['Last Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[0] # note that this will give us an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First Name'] # this is how we get what we need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So that's all a data frame is, it's a table of rows and columns! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's begin to delve further into Pandas with a different data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f restaurant.csv* # 'rm' = 'remove'\n",
    "                            # '-f' means 'force', aka, it will bypass permission checks\n",
    "                            # 'data/restaurant.csv*' means we want to remove any file in our data directory that ends with 'resturant.csv'\n",
    "                            # in total, this command removes any prior file, if it exists\n",
    "\n",
    "!curl 'https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD' -o restaurant.csv\n",
    "                            # 'curl' is a tool to transfer eata from or to a server\n",
    "                            # for more on 'curl' visit (https://curl.haxx.se/docs/manpage.html)\n",
    "\n",
    "# !gzip data/restaurant.csv # compress the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = pd.read_csv('./restaurant.csv', \n",
    "                         encoding = 'utf-8', # for more on UTF-8 check (https://www.w3schools.com/charsets/ref_html_utf8.asp)\n",
    "                         dtype = 'unicode', # we are telling Pandas to read our data as data type object 'Unicode' which will make it a string\n",
    "                         parse_dates = True, # parse our dates that are coming in as strings, as specified above\n",
    "                         infer_datetime_format = True, # we are asking Pandas to infer the format of the datetime strings in the column so as to increase parsing speed\n",
    "                         low_memory = False) # normally Pandas will try to automatically detrmine the dtype, which takes lots of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For column definitions let's check out [the documentation](https://data.cityofnewyork.us/api/views/43nn-pn8j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.head() # show us the first five rows of our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.tail() # show us the last five rows of our data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have successfully read our CSV, let's look at some basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that above all of our data is stored as a non-null object, aka, a string. \n",
    "\n",
    "### But 'Score' is not a string, it's a numerical value. So let's work to alter that in our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"SCORE\"] = pd.to_numeric(restaurants[\"SCORE\"])\n",
    "# we are setting the value of our column equal to itself, but now with the caveat that we want it converted 'to numeric'\n",
    "\n",
    "restaurants.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.SCORE.describe() # let's get some more info on our \"SCORE\" column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"SCORE\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"SCORE\"].hist(bins=50) # let's change the default number of bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a moment to explore what else we can customize in our histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"SCORE\"].hist(bins=50, # use 50 bins\n",
    "                      range=(0,50), # our x-axis will range from 0 to 50\n",
    "                      density=False, # show the raw count; to show normalized count use (density=True)\n",
    "                      figsize=(15,5), # control the size of the plot\n",
    "                      alpha = 0.8 # make plot 20% transparent\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also use KDE (kernel density estimation) to estimate a continuous function, instead of bucketized as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"SCORE\"].plot(\n",
    "    kind = 'kde',\n",
    "    color = 'Black', \n",
    "    xlim = (0, 50),\n",
    "    figsize = (15, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's do some work with dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"GRADE DATE\"].head(10) # show us the first ten values of this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that our dates are stored as strings, which doesn't really help us. So, we can convert all of our dates using the 'to_datetime' function, and format them as illustrated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %m Month as a zero-padded decimal number\n",
    "# %d Day of month as a zero-padded decimal number\n",
    "# %y Year with century as a decimal number\n",
    "\n",
    "restaurants[\"GRADE DATE\"] = pd.to_datetime(restaurants[\"GRADE DATE\"], format=\"%m/%d/%Y\")\n",
    "restaurants[\"RECORD DATE\"] = pd.to_datetime(restaurants[\"RECORD DATE\"], format=\"%m/%d/%Y\")\n",
    "restaurants[\"INSPECTION DATE\"] = pd.to_datetime(restaurants[\"INSPECTION DATE\"], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "restaurants.dtypes # let's check to make sure our code above worked..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[[\"INSPECTION DATE\",\"GRADE DATE\",\"RECORD DATE\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Plot a histogram of our dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"INSPECTION DATE\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exericse 2: Change the number of bins in our histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"INSPECTION DATE\"].hist(bins=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Focus on the dates 1/1/2014 thru 05/31/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"INSPECTION DATE\"].hist(\n",
    "    range = ('1/1/2014', '9/30/2018'),\n",
    "    bins = 57, # number of months in the range, computed manually\n",
    "    figsize = (15,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we've worked with dates, let's look at categorical values...\n",
    "\n",
    "### Sometimes we need categorical values, when we have a variable that has an implicit order, for instance an 'ABC' grade (as we do in our restaurants data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "restaurants[\"BORO\"] =  pd.Categorical(restaurants[\"BORO\"], ordered=False) \n",
    "restaurants[\"GRADE\"] =  pd.Categorical(restaurants[\"GRADE\"], categories = ['A', 'B', 'C'], ordered=True)\n",
    "# 'ordered=True' means that we are saying there are three categories, and 'A' > 'B' > 'C', in that order\n",
    "restaurants[\"VIOLATION CODE\"] =  pd.Categorical(restaurants[\"VIOLATION CODE\"], ordered=False)\n",
    "restaurants[\"CRITICAL FLAG\"] =  pd.Categorical(restaurants[\"CRITICAL FLAG\"], ordered=False)\n",
    "restaurants[\"ACTION\"] =  pd.Categorical(restaurants[\"ACTION\"], ordered=False)\n",
    "restaurants[\"CUISINE DESCRIPTION\"] =  pd.Categorical(restaurants[\"CUISINE DESCRIPTION\"], ordered=False)\n",
    "\n",
    "restaurants.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's delve into a particular column, 'CUISINE DESCRIPTION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"CUISINE DESCRIPTION\"].value_counts()[:5] # give us the 'value_counts' of the first five columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "restaurants[\"CUISINE DESCRIPTION\"].value_counts()[:5].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^ That is super ugly. Let's shorten the name of 'Latin (Cuban, Dominican...' because it is messing up our formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"CUISINE DESCRIPTION\"].replace(\n",
    "    to_replace='Latin (Cuban, Dominican, Puerto Rican, South & Central American)', # replace this...\n",
    "    value = 'Latin American', # with this\n",
    "    inplace=True # inplace=True means we change direclty the dataframe instead of returning a ndw df qithout the deleted value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While we're at it, let's fix the formattig in 'Cafe/Coffee/Tea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"CUISINE DESCRIPTION\"].replace(\n",
    "    to_replace='CafÃ©/Coffee/Tea', # replace this\n",
    "    value = 'Cafe/Coffee/Tea', # with this\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular = restaurants[\"CUISINE DESCRIPTION\"].value_counts()\n",
    "popular[:5].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: What are the 10 most common violation codes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_counts = restaurants[\"VIOLATION CODE\"].value_counts(); \n",
    "\n",
    "violation_counts[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Plot the 10 most common violation codes as a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_counts[0:20].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Plot the numer of inspections across each bourough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[\"BORO\"].value_counts().plot(kind='barh') # the 'h' makes it horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagine we want to get a subset of our data frame based on the columns we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"GRADE DATE\",\"VIOLATION CODE\",\"DBA\",\"SCORE\"] # create a list of the columns we're interested in \n",
    "restaurants[columns].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if instead we wanted to select the rows we're interested in? \n",
    "\n",
    "### Well, to do that, we can generate a list of boolean (True or Fale) values, one for each row of our Data Frame, then use a list to see which rows to keep. \n",
    "\n",
    "### In this case, '04L' is the code for 'has mice'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mice = restaurants[\"VIOLATION CODE\"] == \"04L\"\n",
    "\n",
    "mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_mice = restaurants[mice] # let's apply this new condition to our original df ('restaurants') and store the result \n",
    "                             # in a new data frame called 'has_mice'\n",
    "\n",
    "has_mice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7: Which restaurants have the most mice complaints? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_mice[\"DBA\"].value_counts()[:20] # \"DBA\" represents the name 'Doing Business As\" of the entity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8: Let's pull up all of Subway's mice complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_mice.loc[has_mice[\"DBA\"]==\"SUBWAY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's do some work with Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's count the number of restaurants inspected every day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(\n",
    "    data=restaurants,\n",
    "    index = \"INSPECTION DATE\", # specifies rows\n",
    "    values = \"CAMIS\", # specifies content of cells\n",
    "    aggfunc = \"count\" # ask to count how many different CAMIS values we see\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It looks like that 1900-01-01 value is really throwing us off. Let's get rid of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.drop(pd.to_datetime('1900-01-01'),axis='index',inplace=True)\n",
    "\n",
    "# we use pd.to_datetime to convert '1900-01-01' string to a datetime data type\n",
    "# we use axis='index' to specify that we mean delete a row with that index value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.plot(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.tail(30).plot() # let's look at the last 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.resample('1W').mean().tail(10) # use resample command to change frequency from one to 7 days, then compute the \n",
    "                                     # mean for these days (aka, the sum of total inspections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.resample('7D').mean().plot() # plot the number of inspections over 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9: Plot the total number of inspections over 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.resample('1M').sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also add some basic titles to our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = pivot.resample('7D').mean().plot()\n",
    "plot.set_xlabel(\"Date of Inspection\")\n",
    "plot.set_ylabel(\"Average Number of Inspections (7-day average)\")\n",
    "plot.set_title(\"Analysis of Number of Inspections over Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10: Create a pivot table where we break down the results by boro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boro_pivot = pd.pivot_table(\n",
    "    data = restaurants, #\n",
    "    index = 'INSPECTION DATE', \n",
    "    columns = 'BORO', \n",
    "    values = 'CAMIS', \n",
    "    aggfunc = 'count'\n",
    ")\n",
    "\n",
    "boro_pivot.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11: Delete the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boro_pivot = boro_pivot.drop(pd.to_datetime('1900-01-01'),axis='index') # index means we delete row with that index value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also take a moment to get rid of our 'Missing' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boro_pivot = boro_pivot.drop('Missing',axis='columns')\n",
    "\n",
    "boro_pivot.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's now take some time to explore Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# the '%' is an example of a 'magic command' that allows us to make use of matplotlibs interactivity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0., 5., 0.1) # every sampled value between 0 and 5, at .2 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "plt.plot(t, t, 'r--') # plot t as is with red dashes\n",
    "plt.plot(t, t**2, 'bs') # plot t**2 with blue squares\n",
    "plt.plot(t, t**1.5, 'g^') # plot t**1.5 with green triangles\n",
    "plt.plot(t, 2*np.sin(5*t), 'm-') # plot 2**sin(5*t) with magenta line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, there are lots of predefined styles available, too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues = np.random.normal(size=1000) # an array of 1,000 floats\n",
    "yvalues = np.random.normal(size=1000) # an array of 1,000 floats\n",
    "\n",
    "plt.style.use(u'fivethirtyeight')\n",
    "plt.plot(xvalues, yvalues, 'ro')\n",
    "plt.xlabel(\"Style: fivethirtyeight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's break down all the possibilities with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "\n",
    "# Create the first subfigure\n",
    "sub1 = fig.add_subplot(2,2,1)\n",
    "sub1.set_xlabel('some random numbers')\n",
    "sub1.set_ylabel('more random numbers')\n",
    "sub1.set_title(\"Random scatterplot\")\n",
    "sub1.plot(np.random.randn(1000), np.random.randn(1000), 'r.')\n",
    "\n",
    "# Create the second subfigure\n",
    "sub2 = fig.add_subplot(2,2,2)\n",
    "sub2.hist(np.random.normal(size=500), bins=15)\n",
    "sub2.set_xlabel('sample')\n",
    "sub2.set_ylabel('cumulative sum')\n",
    "sub2.set_title(\"Normal distrubution\")\n",
    "\n",
    "# Create the third subfigure\n",
    "numpoints = 100\n",
    "x = np.linspace(0, 10, num=numpoints)\n",
    "sub3 = fig.add_subplot(2,2,3)\n",
    "sub3.plot(x, np.sin(x) + x + np.random.randn(numpoints), \"r\")\n",
    "sub3.plot(x, np.sin(x) + 0.5 * x + np.random.randn(numpoints), \"g\")\n",
    "sub3.plot(x, np.sin(x) + 2 * x + np.random.randn(numpoints), \"b\")\n",
    "sub3.set_xlabel('x from 0 to 10')\n",
    "sub3.set_ylabel('function value')\n",
    "\n",
    "# Create the fourth subfigure\n",
    "sub4 = fig.add_subplot(2,2,4)\n",
    "x = np.random.randn(10000)\n",
    "y = np.random.randn(10000)\n",
    "sub4.hist2d(x,y,bins=100);\n",
    "sub4.set_xlabel('x axis title')\n",
    "sub4.set_ylabel('y axis title')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"normalvars.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit more on what can be done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can split multiple series into subplots with a single argument\n",
    "\n",
    "variables = pd.DataFrame({'normal': np.random.normal(size=100), \n",
    "                       'gamma': np.random.gamma(1, size=100), \n",
    "                       'poisson': np.random.poisson(size=100)})\n",
    "\n",
    "variables.cumsum(0).plot(subplots=True,figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, have some series displayed on secondary y-axis\n",
    "\n",
    "variables.cumsum(0).plot(secondary_y='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "for i,var in enumerate(['normal','gamma','poisson']):\n",
    "    variables[var].cumsum(0).plot(ax=axes[i], title=var)\n",
    "axes[0].set_ylabel('cumulative sum (normal)')\n",
    "axes[1].set_ylabel('cumulative sum (gamma)')\n",
    "axes[2].set_ylabel('cumulative sum (poisson)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check out a new data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('/Users/siegmanA/Desktop/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('Pclass').Survived.sum() # How many survivors are there based on passenger class? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('Pclass').Survived.sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(['Sex','Pclass']).Survived.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(['Sex','Pclass']).Survived.mean().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_counts = pd.crosstab([titanic.Pclass, titanic.Sex], titanic.Survived.astype(bool))\n",
    "death_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_counts.plot(kind='bar', stacked=True, color=['red','blue'], grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_counts.div(death_counts.sum(1).astype(float), axis=0).plot(kind='barh', stacked=True, color=['red','blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How were fares distributed aboard the titanic? \n",
    "\n",
    "titanic[\"Fare\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13: How do we divide our histogram into 30 bins? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Fare\"].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Plots\n",
    "\n",
    "### Rather than purely represent the underlying data, this is an _estimate_ of the underlying true distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Fare\"].plot(kind='kde', xlim=(0,100), ylim=(0,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Fare\"].plot(kind='kde', xlim=(0,600)) # notice what happens when we change our xlim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots\n",
    "\n",
    "### Think of a boxplot as viewing the data 'from above'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = titanic.boxplot(column='Age', by='Pclass', grid=False, figsize=(8,8))\n",
    "for i in [1,2,3]:\n",
    "    y = titanic.Age[titanic.Pclass==i].dropna()\n",
    "    x = np.random.normal(i, 0.04, size=len(y)) # Add some random \"jitter\" to the x-axis\n",
    "\n",
    "    plt.plot(x, y, 'r.', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = titanic.plot(kind=\"scatter\", x='Age', y='Siblings/Spouses Aboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = titanic.plot(kind=\"scatter\", x='Age', y='Siblings/Spouses Aboard',xlim=[0,100], ylim=[0,10],figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can even go so far as to assign variables to either the size or symbols of their colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = titanic.plot(kind='scatter', x='Age', y='Siblings/Spouses Aboard', xlim=[0,100], ylim=[0,10], \n",
    "                    figsize=(5,5), c=titanic['Siblings/Spouses Aboard'], s=60, cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hexagonal Bin Plot\n",
    "\n",
    "### This is perfect for when you have a larger number of points to display. It's also useful if your data are too dense to plot each point individually in a scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( np.random.randn(10000, 2), columns=['a', 'b'])\n",
    "df['b'] = df['b'] + np.arange(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='a', y='b', figsize=(6,4), alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='hexbin', x='a', y='b', gridsize=40,figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
