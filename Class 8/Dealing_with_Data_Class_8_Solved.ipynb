{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For today's class, don't worry too much about following along with the code. Rather, consider this an exercise in better understanding what the skills you are learning in this class look like when applied to a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Let's Explore our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 5000 # this just let's us change the Jupyter display to see more values. \n",
    "pd.options.display.max_columns = 100 # again, we're just allowing ourselves to see more values re: columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For more on options and settings check out https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('propensity_data.csv') # we are reading in our csv and assinging it the value 'data'. \n",
    "                                          # you can, of course, name this whatever you'd like!\n",
    "\n",
    "# fun fact, you can use the 'Tab' button to auto-complete a file name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() # '.head()' will give you the first 5 rows. '.tail()' will give you the last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(data) # let's get a list of all the column names in our file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some definitions for us: \n",
    "\n",
    "> *pageID*: A random ID assigned to the instance.\n",
    "\n",
    "> *paywall:* What paywall experience the visitor got.\n",
    "\n",
    "> *time:* What time the content was accessed.\n",
    "\n",
    "> *daysSinceFirstSeen:* Days since we first saw the visitor.\n",
    "\n",
    "> *section:* On what section of the site did the article view occur? \n",
    "\n",
    "> *visitNum:* Visit number.\n",
    "\n",
    "> *pageNum:* Page number within the visit.\n",
    "\n",
    "> *registered:* Whether or not the user is registered.\n",
    "\n",
    "> *edu:* Whether or not the user is visiting from a '.edu' domain.\n",
    "\n",
    "> *mobile:* Whether or not the user is on a mobile phone.\n",
    "\n",
    "> *mac:* Whether or not the user is using an Apple device.\n",
    "\n",
    "> *converted:* A binary value, '0' for did not convert, '1' for did convert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() # some basic info on our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count() # this is telling us the number of values we have per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample() # a random sample row from our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[3] # .iloc is how we index through a data frame. In this case, we're asking for the first row\n",
    "             # remember, too, Python is 0-index, so the 3rd value is actually the fourth row!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[3,2] # [row, column] aka, the fourth row, third column (time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(random_state=1) # random_state ensures that we all get the same values :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ^ We can see that our user, #536022, was last seen 194 days ago when he/she visited the Personal Finance section three times , and he/she did not convert. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the average conversion rate for our sample users? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_conversion = data['converted'].mean()\n",
    "\n",
    "avg_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below we are just reformatting our value for ease of reading\n",
    "\n",
    "percentage = '{0:.2f}'.format(avg_conversion) \n",
    "print(percentage + \" = to two decimals places.\")\n",
    "\n",
    "percentage = '{0:.4f}'.format(avg_conversion)\n",
    "print(percentage + \" = to four decimal places.\")\n",
    "\n",
    "percentage = '{0:.6f}'.format(avg_conversion)\n",
    "print(percentage + \" = to six decimal places.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the difference in conversion rate between locked and open paywall users? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_by_paywall = data.groupby('paywall').mean()\n",
    "conversion_by_paywall['converted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the difference in conversion rate as it relates to visit numbers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conversion_by_paywall = data.groupby('visitNum').mean()\n",
    "conversion_by_paywall['converted'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['visitNum']==1345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['visitNum']==642]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the difference in conversion rate as it relates to section? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_by_paywall = data.groupby('section').mean()\n",
    "conversion_by_paywall['converted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about some graphical insights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to use Linear Regression, we can't have text values, but, right now 'paywall' and 'section' are all text. A computer doesn't know what Open versus Locked means, nor does it know what Funds versus Personal Finance means. So, we create dummy variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(data['section'])\n",
    "dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data,dummy],axis=1) # axis=1 means we are adding by column, not the row\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy2 = pd.get_dummies(data['paywall'])\n",
    "data = pd.concat([data,dummy2],axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lastly, using a raw number for the hour of the day visited is fine, but it would be more helpful if we can capture cyclical effects. For instance, 11pm and 1 am are more similar than 11pm and 5 pm â€“ using the raw number wouldn't capture that relationship. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "data['time'] = pd.to_datetime(data['time'],errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with datetime is notoriously frustrating. \n",
    "\n",
    "## For documentation check out https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['weekday'] = data['time'].dt.weekday # Monday = 0, Sunday = 6\n",
    "data['weekday'] = (data['weekday'] < 5).astype(int) \n",
    "\n",
    "data['morning'] = data['time'].dt.hour # 0 - 23\n",
    "data['morning'] = (data['morning'] < 12).astype(int)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's remind ourselves of the columns we have after implementing our dummy variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here are two ways to select numeric data and keep columns\n",
    "\n",
    "numeric_data = data.select_dtypes(exclude=['object', 'datetime64'])\n",
    "X1 = numeric_data.loc[:, ~numeric_data.columns.isin(['converted', 'pageID'])]\n",
    "\n",
    "### OR more pythonically\n",
    "\n",
    "keep_columns = [x for x in numeric_data.columns if x not in ['converted','pageID']]\n",
    "X2 = numeric_data.loc[:, keep_columns]\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['time'],axis=1,inplace=True) # inplace = True means it's a permanent change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['daysSinceFirstSeen','visitNum','pageNum','registered','edu','mobile','mac','Funds','Personal Finance','Retirement Planning','Stock Tips','Locked','Open','weekday','morning']] \n",
    "y = data['converted']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .4, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame(y_pred).rename(columns=lambda x: 'PredictedValue')\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predictions'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAll = pd.concat([data,data2],axis=1)\n",
    "dataAll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(regr.coef_,X.columns,columns=['Coefficient'])\n",
    "\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE (Root Mean Squared Error) is the Standard Deviation of the residuals (prediction error). The residuals are thus a measure of how far from the regression line the data points are. \n",
    "\n",
    "### If there is a perfect correlation (correlation coefficient = 1), the RMSE will be 0, because all the points will lie on the regression line, thus, there are no errors. \n",
    "\n",
    "### So, we didn't do too bad with an RMSE of approximately .034!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But, let's try a logistic regression, which is more appropriate given that we're trying to do a binary classification (convert versus not convert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "X = data[['pageID','daysSinceFirstSeen','visitNum','pageNum','registered','edu','mobile','mac','Funds','Personal Finance','Retirement Planning','Stock Tips','Locked','Open','weekday','morning']] \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .4, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"X_train_info\" + str(X_train.describe()))\n",
    "#print(\"X_test_info\" + str(X_test.describe()))\n",
    "#print(\"y_train_info\" + str(y_train.describe()))\n",
    "#print(\"y_test_info\" + str(y_test.describe(())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train, sample_weight=None)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = logreg.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does this seem too good to be true? Because it is! Basically, because the average conversion rate is so low, the model just 'assumed' the default 'not converted' for most samples, which would be correct 99.8% of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "    train_predictions = clf.predict_proba(X_test)\n",
    "    ll = log_loss(y_test, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
